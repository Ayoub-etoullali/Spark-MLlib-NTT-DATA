{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47bbd79a",
   "metadata": {},
   "source": [
    "# Load & Info & Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "39c349da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the sessions dataset\n",
    "X = pd.read_csv('../data/train_merge_tfidf.csv')\n",
    "y = pd.read_csv('../data/y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d36d014",
   "metadata": {},
   "source": [
    "## selector3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "823194ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1', '2', '11', '12', '13', '76', '87', '128', '197', '246', '296',\n",
      "       '320', '337', '376', '389', '394', '397', '433', '462', '473', '475',\n",
      "       '479', '522'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [5 8] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# SelectKBest: est une methode de sélection de caractéristiques qui permet de sélectionner les K meilleures caractéristiques\n",
    "# en fonction d'un test statistique \n",
    "selector3 = SelectKBest(f_classif, k=23)\n",
    "selector3.fit(X, y)\n",
    "\n",
    "selected_feature_indices = selector3.get_support(indices=True)\n",
    "\n",
    "selected_feature_names = X.columns[selected_feature_indices]\n",
    "\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd67ed5",
   "metadata": {},
   "source": [
    "# Selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6b2bbc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', '2', '11', '12', '13', '76', '87', '128', '197', '246', '296',\n",
       "       '320', '337', '376', '389', '394', '397', '433', '462', '473', '475',\n",
       "       '479', '522'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "59e5ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[selected_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ea115193",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:10000]\n",
    "y = y[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c4e3df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 23)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "632cca1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "cc263bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# https://www.kaggle.com/davidgasquez/ndcg-scorer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    \n",
    "    \"\"\"Discounted cumulative gain (DCG) at rank K.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array, shape = [n_samples, n_classes]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "    \n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):\n",
    "    \n",
    "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank K.\n",
    "\n",
    "    Normalized Discounted Cumulative Gain (NDCG) measures the performance of a\n",
    "    recommendation system based on the graded relevance of the recommended\n",
    "    entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal\n",
    "    ranking of the entities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_truth : array, shape = [n_samples]\n",
    "        Ground truth (true labels represended as integers).\n",
    "    predictions : array, shape = [n_samples, n_classes]\n",
    "        Predicted probabilities.\n",
    "    k : int\n",
    "        Rank.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> ground_truth = [1, 0, 2]\n",
    "    >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    1.0\n",
    "    >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    0.6666666666\n",
    "    \"\"\"\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(predictions.shape[1] + 1))\n",
    "    T = lb.transform(ground_truth)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predictions):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82a3f8",
   "metadata": {},
   "source": [
    "# Fiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "afcbb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {\n",
    "'max_depth': sp_randint(3, 20),\n",
    "'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "'min_child_weight': [0.25,0.5, 1.0, 3.0, 5.0, 7.0],\n",
    "'gamma': [0, 0.25, 0.3,0.35,0.45,0.5,0.6,0.8,1.0],\n",
    "'reg_lambda': [0.1,0.2,0.4,0.5,0.6,0.8,1.0,10.0],\n",
    "'n_estimators':[100,200,500,1000,2000],\n",
    "'colsample_bytree':[0.1,0.3,0.5,1],\n",
    "'colsample_bylevel':[0.1,0.3,0.5,1]\n",
    "}\n",
    "\n",
    "\n",
    "gb = xgb.XGBClassifier(objective='multi:softmax',eval_metric= 'mlogloss')\n",
    "\n",
    "clf = RandomizedSearchCV(gb, param_grid,n_jobs=-1,verbose=10,scoring=ndcg_scorer, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "9a5c2166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  7,  7, ...,  7, 10,  7])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_target = le.fit_transform(y['target_column_name'])\n",
    "\n",
    "y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50040823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X,y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2112b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca548018",
   "metadata": {},
   "source": [
    "# Train ndcg score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe14f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#Train ndcg score\n",
    "\n",
    "s = ndcg_score(y_target, pred_y, k=5)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82608ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a898df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115aadc",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f789bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_target, pred_y)\n",
    "report = classification_report(y_target, pred_y)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659020f",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c505c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load and preprocess the test data\n",
    "test_data = pd.read_csv(\"../data/test_merge_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61164bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the trained model\n",
    "test_predictions = clf.predict(test_data[selected_feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af5c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc14d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y['target_column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge = y\n",
    "train_merge['country_destination'] = y['target_column_name'].astype('category')\n",
    "\n",
    "# Map predicted class labels to category codes\n",
    "test_data['predicted_country'] = pd.Categorical(test_predictions, categories=train_merge['country_destination'].cat.categories)\n",
    "\n",
    "test_data['predicted_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predicted_country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predicted_country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70825061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the countplot\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.figure(figsize=(8, 6))  # Optional: Set the figure size\n",
    "\n",
    "# Calculate percentages\n",
    "total_samples = len(test_data)\n",
    "ax = sns.countplot(x='predicted_country', data=test_data, order=test_data['predicted_country'].value_counts().index)\n",
    "\n",
    "# Add percentages to the plot\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{height/total_samples*100:.2f}%', (p.get_x() + p.get_width() / 2., height), ha='center', va='bottom')\n",
    "\n",
    "plt.title(\"Predicted Country Distribution\", size=13)\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.xticks(rotation=90)  # Optional: Rotate x-axis labels if needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../data/sample_submission_NDF.csv\")\n",
    "\n",
    "# Prepare submission file\n",
    "submission['country'] = test_data[['predicted_country']]\n",
    "\n",
    "submission.to_csv('../data/submission_XGBoost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d0cd1",
   "metadata": {},
   "source": [
    "# +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a11771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "\n",
    "features = selected_feature_names\n",
    "importances = clf.best_estimator_.feature_importances_\n",
    "\n",
    "indices = (np.argsort(importances))[-25:]\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='r', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e632758",
   "metadata": {},
   "source": [
    "# Select top 80% of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_80 = int(len(clf.best_estimator_.feature_importances_)*0.8)\n",
    "\n",
    "indices = (np.argsort(importances))[::-1][:top_80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2483c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top features from the DataFrame X\n",
    "X_new = X.iloc[:, indices]\n",
    "\n",
    "# Create a list of the selected column names\n",
    "col_lst_new = [selected_feature_names[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87edfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Data matrix\")\n",
    "print(X_new.shape)\n",
    "print(y.shape)\n",
    "print(len(col_lst_new))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b883b",
   "metadata": {},
   "source": [
    "# Train on top 80% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bfa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7700f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb92a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_new,y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = clf.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d68efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train ndcg score\n",
    "\n",
    "s = ndcg_score(y_target, pred_y, k=5)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbc51a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8daa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_target, pred_y)\n",
    "report = classification_report(y_target, pred_y)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "\n",
    "features = selected_feature_names\n",
    "importances = clf.best_estimator_.feature_importances_\n",
    "\n",
    "indices = (np.argsort(importances))[-25:]\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='r', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
