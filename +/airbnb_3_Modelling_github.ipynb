{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aBegC116XlF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from datetime import datetime, date\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import joblib\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2g5-TnSr6XlJ"
   },
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Function takes filename and returns csr matrix .\n",
    "    \n",
    "    parameters:  filename\n",
    "    \n",
    "    returns: csr matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MaEgVdur6XlM"
   },
   "outputs": [],
   "source": [
    "train_merge_tfidf = load_sparse_csr('../data/train_merge_tfidf.npz')\n",
    "\n",
    "test_merge_tfidf = load_sparse_csr('../data/test_merge_tfidf.npz')\n",
    "\n",
    "y = np.load('../data/y.npy', allow_pickle=True)\n",
    "\n",
    "with open(\"../data/col_lst.txt\", \"rb\") as fp:\n",
    "    \n",
    "    col_lst = pickle.load(fp)\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6ZffrRO6XlP",
    "outputId": "5639dfb2-d214-4fd5-d6ba-7b2376c127b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data matrix\n",
      "(73815, 523)\n",
      "(62096, 523)\n",
      "(73815,)\n",
      "523\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Data matrix\")\n",
    "print(train_merge_tfidf.shape)\n",
    "print(test_merge_tfidf.shape)\n",
    "print(y.shape)\n",
    "print(len(col_lst))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqVc2xqZ6XlT",
    "outputId": "1f928ec6-0598-435e-843b-50779f9b3440"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  7,  7, ...,  7,  7,  7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhrNnoRj6XlW"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/davidgasquez/ndcg-scorer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    \n",
    "    \"\"\"Discounted cumulative gain (DCG) at rank K.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array, shape = [n_samples, n_classes]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "    \n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):\n",
    "    \n",
    "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank K.\n",
    "\n",
    "    Normalized Discounted Cumulative Gain (NDCG) measures the performance of a\n",
    "    recommendation system based on the graded relevance of the recommended\n",
    "    entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal\n",
    "    ranking of the entities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_truth : array, shape = [n_samples]\n",
    "        Ground truth (true labels represended as integers).\n",
    "    predictions : array, shape = [n_samples, n_classes]\n",
    "        Predicted probabilities.\n",
    "    k : int\n",
    "        Rank.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> ground_truth = [1, 0, 2]\n",
    "    >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    1.0\n",
    "    >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    0.6666666666\n",
    "    \"\"\"\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(predictions.shape[1] + 1))\n",
    "    T = lb.transform(ground_truth)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predictions):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NT6jKhsu6XlY"
   },
   "source": [
    "# Testing with lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSdOgE_a6XlZ"
   },
   "outputs": [],
   "source": [
    "params =  {'C':[0.0001, 0.001, 0.01]}\n",
    "\n",
    "lr = linear_model.LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\")\n",
    "\n",
    "clf = RandomizedSearchCV(lr, params, verbose=10, n_iter=3 ,n_jobs=-1,scoring=ndcg_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_tfidf = train_merge_tfidf[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x523 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 482466 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  7,  7, ...,  7, 10,  7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdWvWMpk6Xlc",
    "outputId": "edf8b543-e588-431d-ccfa-554923b5c57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=LogisticRegression(multi_class=&#x27;multinomial&#x27;),\n",
       "                   n_iter=3, n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: [0.0001, 0.001, 0.01]},\n",
       "                   scoring=make_scorer(ndcg_score, needs_proba=True, k=5),\n",
       "                   verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=LogisticRegression(multi_class=&#x27;multinomial&#x27;),\n",
       "                   n_iter=3, n_jobs=-1,\n",
       "                   param_distributions={&#x27;C&#x27;: [0.0001, 0.001, 0.01]},\n",
       "                   scoring=make_scorer(ndcg_score, needs_proba=True, k=5),\n",
       "                   verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(multi_class='multinomial'),\n",
       "                   n_iter=3, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.0001, 0.001, 0.01]},\n",
       "                   scoring=make_scorer(ndcg_score, needs_proba=True, k=5),\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_merge_tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Xwmq5LN6Xle"
   },
   "outputs": [],
   "source": [
    "pred_y = clf.predict_proba(train_merge_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmRQYg3K6Xlg",
    "outputId": "62e3dd5e-0091-44d3-a4a4-9dd7b70efa0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.0001}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  7,  7, ...,  7, 10,  7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.23165447e-005, 6.92595999e-005, 1.99035121e-006, ...,\n",
       "        0.00000000e+000, 3.36127854e-001, 5.48935407e-002],\n",
       "       [5.77556181e-002, 5.98021666e-002, 4.77098614e-002, ...,\n",
       "        1.08157180e-023, 1.19897760e-001, 8.25321900e-002],\n",
       "       [9.04201321e-003, 1.15454040e-002, 3.53541585e-003, ...,\n",
       "        1.65935567e-121, 2.18484932e-001, 9.93647568e-002],\n",
       "       ...,\n",
       "       [7.28324938e-002, 7.19712121e-002, 7.10799660e-002, ...,\n",
       "        5.73478348e-002, 8.74861939e-002, 6.60502134e-002],\n",
       "       [3.70166839e-003, 5.15289028e-003, 1.06342757e-003, ...,\n",
       "        7.16385675e-162, 2.45938245e-001, 9.42876307e-002],\n",
       "       [3.10449510e-003, 4.39408500e-003, 8.40465551e-004, ...,\n",
       "        1.20072270e-169, 2.50622444e-001, 9.29741995e-002]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ha60jr4A6Xli",
    "outputId": "237d8301-ae30-4d9d-f783-a4be41574cc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8198739963386653"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train ndcg score\n",
    "\n",
    "s = ndcg_score(y, pred_y, k=5)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTee-j3o6Xln"
   },
   "source": [
    "# Testing with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScV4kIWQ6Xlo"
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/53782169/random-forest-tuning-with-randomizedsearchcv\n",
    "\n",
    "params = {\n",
    "'n_estimators' : [200, 700, 800, 1000, 1200],\n",
    "'max_depth' : [15, 20, 25, 30, 35, 50],\n",
    "'min_samples_split' : [2, 3, 5, 8],\n",
    "'min_samples_leaf' : [1, 2, 5, 10] }\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "clf = RandomizedSearchCV(rf, params, verbose=10,n_jobs=-1,scoring=ndcg_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9lIvEau76Xls",
    "outputId": "fafb2cc3-5213-4cba-b26d-17bf9dc6e7d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_merge_tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ka5L49_D6Xlu"
   },
   "outputs": [],
   "source": [
    "pred_y = clf.predict_proba(train_merge_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-CostsR6Xlw",
    "outputId": "2db5e624-4072-4c89-92bc-5a5190fdd334"
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMhSbB8f6Xly",
    "outputId": "acb31310-69cb-478c-a762-b359f822ccdf"
   },
   "outputs": [],
   "source": [
    "#Train ndcg score\n",
    "\n",
    "s = ndcg_score(y, pred_y, k=5)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEVnCagd6Xl1"
   },
   "source": [
    "# Testing with Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzan_Uwj6Xl2"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "'max_depth': sp_randint(3, 20),\n",
    "'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "'min_child_weight': [0.25,0.5, 1.0, 3.0, 5.0, 7.0],\n",
    "'gamma': [0, 0.25, 0.3,0.35,0.45,0.5,0.6,0.8,1.0],\n",
    "'reg_lambda': [0.1,0.2,0.4,0.5,0.6,0.8,1.0,10.0],\n",
    "'n_estimators':[100,200,500,1000,2000],\n",
    "'colsample_bytree':[0.1,0.3,0.5,1],\n",
    "'colsample_bylevel':[0.1,0.3,0.5,1]\n",
    "}\n",
    "\n",
    "\n",
    "gb = xgb.XGBClassifier(objective='multi:softmax',eval_metric= 'mlogloss')\n",
    "\n",
    "clf = RandomizedSearchCV(gb, param_grid,n_jobs=-1,verbose=10,scoring=ndcg_scorer, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiI_ESpUYIp2",
    "outputId": "b5649898-aa7e-47bd-e624-5112b935e4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10], got [ 0  1  2  3  4  5  6  7  8 10 11]\n\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6 7 8 9], got [ 0  1  2  3  4  5  6  7 10 11]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_merge_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10], got [ 0  1  2  3  4  5  6  7  8 10 11]\n\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"C:\\Users\\ayoub\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6 7 8 9], got [ 0  1  2  3  4  5  6  7 10 11]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_merge_tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDSY54616Xl6"
   },
   "outputs": [],
   "source": [
    "pred_y = clf.predict_proba(train_merge_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwFAOY-Q6Xl8",
    "outputId": "f5ea420f-039e-48c9-9e64-9a318981b8a1"
   },
   "outputs": [],
   "source": [
    "# Train ndcg score\n",
    "\n",
    "s = ndcg_score(y, pred_y, k=5)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0vk5dyfM6Xl-",
    "outputId": "c7ad6f2d-e63c-4445-fb1a-bc139dd87837"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#feature importance\u001b[39;00m\n\u001b[0;32m      3\u001b[0m features \u001b[38;5;241m=\u001b[39m col_lst\n\u001b[1;32m----> 4\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importances_\u001b[49m\n\u001b[0;32m      5\u001b[0m indices \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39margsort(importances))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m25\u001b[39m:]\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m12\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "#feature importance\n",
    "\n",
    "features = col_lst\n",
    "importances = clf.feature_importances_\n",
    "indices = (np.argsort(importances))[-25:]\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='r', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXkzkfOM6XmA",
    "outputId": "2bd2999d-7dae-4a38-aa1f-06abd179ef4b"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43691380/how-to-save-load-xgboost-model\n",
    "\n",
    "#save model\n",
    "\n",
    "joblib.dump(clf,'../data/clf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3D3_cCm6XmC"
   },
   "outputs": [],
   "source": [
    "#load saved model\n",
    "\n",
    "clf = joblib.load('../data/clf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-6BIuhD08jP"
   },
   "source": [
    "# Select top 80% of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpGBXMBP08jP"
   },
   "outputs": [],
   "source": [
    "top_80 = int(len(clf.feature_importances_)*0.8)\n",
    "\n",
    "indices = (np.argsort(importances))[::-1][:top_80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EkdEiiwo08jS"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48099075/how-to-get-columns-from-big-sparse-csc-matrix\n",
    "\n",
    "cols = []\n",
    "\n",
    "for i in indices:\n",
    "    \n",
    "    cols.append(train_merge_tfidf[:,i])\n",
    "    \n",
    "train_merge_tfidf_new = hstack(cols)\n",
    "\n",
    "cols = []\n",
    "\n",
    "for i in indices:\n",
    "    \n",
    "    cols.append(test_merge_tfidf[:,i])\n",
    "    \n",
    "test_merge_tfidf_new = hstack(cols)\n",
    "\n",
    "col_lst_new = []\n",
    "\n",
    "for i in indices:\n",
    "    \n",
    "     col_lst_new.append(col_lst[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cCp2Hmc08jU",
    "outputId": "eafc6e2d-2a21-419c-a823-41e292947076"
   },
   "outputs": [],
   "source": [
    "print(\"Final Data matrix\")\n",
    "print(train_merge_tfidf_new.shape)\n",
    "print(test_merge_tfidf_new.shape)\n",
    "print(y.shape)\n",
    "print(len(col_lst_new))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRTNlI2V08jW"
   },
   "source": [
    "# Train on top 80% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "By5MQDiF08jX",
    "outputId": "f8273a32-da12-4bc8-bc05-aa62e63d3004"
   },
   "outputs": [],
   "source": [
    "clf.fit(train_merge_tfidf_new,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_E6kvpNV08jZ"
   },
   "outputs": [],
   "source": [
    "pred_y = clf.predict_proba(train_merge_tfidf_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzWgFbyU08jb",
    "outputId": "6e986c99-22b6-42e4-c796-cd2fdc1acec7"
   },
   "outputs": [],
   "source": [
    "# Train ndcg score\n",
    "\n",
    "s = ndcg_score(y, pred_y, k=5)\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EVW-gvQN08jd",
    "outputId": "d79d214a-9d43-4afd-dbcd-8dd705248b96"
   },
   "outputs": [],
   "source": [
    "#feature importance\n",
    "\n",
    "features = col_lst_new\n",
    "importances = clf.feature_importances_\n",
    "indices = (np.argsort(importances))[-25:]\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='r', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3zyXbDD_08jg"
   },
   "source": [
    "# Best score = 13% of the Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33V9GEpG6XmF",
    "outputId": "3b4a7458-2685-4a7e-df92-842ff7370c76"
   },
   "outputs": [],
   "source": [
    "#test csv\n",
    "\n",
    "test_df = pd.read_csv('../data/test_users.csv')\n",
    "\n",
    "test_id = test_df['id'].values\n",
    "\n",
    "test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0S81TZSp6XmH"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kevinwu06/feature-importance-w-xgboost\n",
    "\n",
    "pred = clf.predict_proba(test_merge_tfidf)\n",
    "\n",
    "ids = []\n",
    "countries = []\n",
    "\n",
    "# Taking the 5 classes with highest probabilities\n",
    "\n",
    "for i in range(len(test_id)):\n",
    "    idx = test_id[i]\n",
    "    ids += [idx] * 5\n",
    "    countries += le.inverse_transform(np.argsort(pred[i])[::-1][:5]).tolist()\n",
    "    \n",
    "# Generate submission\n",
    "\n",
    "sub = pd.DataFrame({\"id\" : ids,\"country\" : countries})\n",
    "\n",
    "sub.to_csv('../data/kag_sub.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13fNxIjH08jk",
    "outputId": "12035812-0fcf-4dc6-a6d1-8adeff726e79"
   },
   "outputs": [],
   "source": [
    "Image(filename='../data/score.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtjyTEY008jm"
   },
   "source": [
    "# Comparison with other submitted notebooks ordered by best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZNfpe7y08jm"
   },
   "source": [
    "1) https://www.kaggle.com/zhugds/test-script - score = 0.87008\n",
    "\n",
    "== This user doesnt make use of the sessions data, instead uses the entire train data.\n",
    "\n",
    "== But from our model, we know secs_elapsed and other actions are among the most imp features.\n",
    "\n",
    "== Thus, we get a better score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_gsXahp08jm"
   },
   "source": [
    "2) https://www.kaggle.com/wallinm1/script-0-1 - score = 0.86987\n",
    "\n",
    "== This user also doesnt make use of the sessions data, instead uses the entire train data.\n",
    "\n",
    "== But from our model, we know secs_elapsed and other actions are among the most imp features.\n",
    "\n",
    "== Thus, we get a better score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHooDNZI08jn"
   },
   "source": [
    "3) https://www.kaggle.com/kapetis/script-0-1 - score = 0.86987\n",
    "\n",
    "== This user also doesnt make use of the sessions data, instead uses the entire train data.\n",
    "\n",
    "== But from our model, we know secs_elapsed and other actions are among the most imp features.\n",
    "\n",
    "== Thus, we get a better score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kq5Hv09f08jn"
   },
   "source": [
    "4) https://www.kaggle.com/foutik/script-cleaning-data - score = 0.86969\n",
    "\n",
    "== This user also doesnt make use of the sessions data, instead uses the entire train data.\n",
    "\n",
    "== But from our model, we know secs_elapsed and other actions are among the most imp features.\n",
    "\n",
    "== Thus, we get a better score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2uAhG1L08jn"
   },
   "source": [
    "5) https://www.kaggle.com/michaelpawlus/xgb-feature-exploration - score = 0.85655\n",
    "\n",
    "== This user also doesnt make use of the sessions data, instead uses the entire train data.\n",
    "\n",
    "== But from our model, we know secs_elapsed and other actions are among the most imp features.\n",
    "\n",
    "== Thus, we get a better score."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "airbnb_3_Modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
